{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QNN on Pynq\n",
    "\n",
    "This notebook covers how to use low quantized Neural Networks on Pynq for inference on MNIST dataset by using LFC network composed of 4 fully connected layers with 1024 neurons each. There are 2 networks using different precision: \n",
    "\n",
    "- LFCW1A1 using 1 bit weights and 1 activation,\n",
    "- LFCW1A2 using 1 bit weights and 2 activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LFC and MNIST\n",
    "\n",
    "This notebook performs inference on MNIST test set from http://yann.lecun.com/exdb/mnist/ which contains 10000 pictures of handwritten digits. The LFC network requires MNIST formatted input data, that's why the binary test file can be directly loaded. All other images have to be formatted to this specification (refer to url and LFC webcam examples).\n",
    "\n",
    "At first you need to download mnist test set and labels using wget and unzip the archive as shown below:\n",
    "In order to be able to compare the inferred classes against the expected labels we first read the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #get\n",
    "# !wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz \n",
    "# !wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz \n",
    "# #unzip    \n",
    "# !gzip -d t10k-images-idx3-ubyte.gz\n",
    "# !gzip -d t10k-labels-idx1-ubyte.gz\n",
    "\n",
    "#read labels\n",
    "labels = []\n",
    "with open(\"/home/xilinx/jupyter_notebooks/bnn/t10k-labels-idx1-ubyte\",\"rb\") as lbl_file:\n",
    "    #read magic number and number of labels (MSB first) -> MNIST header\n",
    "    magicNum = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "    countLbl = int.from_bytes(lbl_file.read(4), byteorder=\"big\")\n",
    "    #now the labels are following byte-wise\n",
    "    for idx in range(countLbl):\n",
    "        labels.append(int.from_bytes(lbl_file.read(1), byteorder=\"big\"))\n",
    "    lbl_file.close()\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hardware Inference\n",
    "\n",
    "First of all a classifier needs to be instantiated. Using the LfcClassifier will allow to classify MNIST formatted images utilizing LFC network. There are two different runtimes available: hardware accelerated and pure software environment.\n",
    "\n",
    "Once a classifier is instantiated the inference on MNIST images can be started using `classify_mnist` or `classify_mnists` methods - for both single and multiple images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: \n",
    "##### W1A1 - 1 bit weights and 1 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcW1A1_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A1,\"mnist\",bnn.RUNTIME_HW)\n",
    "lfcW1A1_classifier.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_W1A1 = lfcW1A1_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: \n",
    "#### W1A2 - 1 bit weights and 2 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcW1A2_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A2,\"mnist\",bnn.RUNTIME_HW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_W1A2 = lfcW1A2_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: \n",
    "#### W2A2 - 2 bit weights and 2 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfcW2A2_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW2A2,\"mnist\",bnn.RUNTIME_HW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_W2A2 = lfcW2A2_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sum(result_W2A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Software accelerated inference\n",
    "\n",
    "In comparison to previous runs the inference can be performed in pure software runtime utilizing PYNQs ARM core. Let's only take the first 10 pictures to get results within a narrow time frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/xilinx/jupyter_notebooks/bnn/10_mnist_pictures\", \"wb\") as out_file:\n",
    "    with open(\"/home/xilinx/jupyter_notebooks/bnn/t10k-images-idx3-ubyte\",\"rb\") as img_file:\n",
    "        #copy magic number\n",
    "        out_file.write(img_file.read(4))\n",
    "        #set number of images\n",
    "        img_file.read(4)\n",
    "        out_file.write(bytearray.fromhex('0000000A'))        \n",
    "        #copy row and column information\n",
    "        out_file.write(img_file.read(8))\n",
    "        \n",
    "        #copy 10 pictures (one is 28x28, 1 pixel is 1 byte)\n",
    "        out_file.write(img_file.read(28*28*10))\n",
    "        img_file.close()\n",
    "        out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SW Inference with W2A2:\n",
      "Inference took 2506462.03 microseconds, 250646.20 usec per image\n",
      "Classification rate: 3.99 images per second\n"
     ]
    }
   ],
   "source": [
    "# print(\"SW Inference with W1A1:\")\n",
    "# sw_lfcW1A1_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A1,\"mnist\",bnn.RUNTIME_SW)\n",
    "# sw_resultW1A1 = sw_lfcW1A1_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/10_mnist_pictures\")\n",
    "# print(\"\\nSW Inference with W1A2:\")\n",
    "# sw_lfcW1A2_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW1A2,\"mnist\",bnn.RUNTIME_SW)\n",
    "# sw_resultW1A2 = sw_lfcW1A2_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/10_mnist_pictures\")\n",
    "print(\"\\nSW Inference with W2A2:\")\n",
    "sw_lfcW2A2_classifier = bnn.LfcClassifier(bnn.NETWORK_LFCW2A2,\"mnist\",bnn.RUNTIME_SW)\n",
    "sw_resultW2A2 = sw_lfcW2A2_classifier.classify_mnists(\"/home/xilinx/jupyter_notebooks/bnn/10_mnist_pictures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(sw_resultW2A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen, pure software runtime is much slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "### Inference time\n",
    "\n",
    "##### Hardware\n",
    "\n",
    "Results can be visualized using matplotlib. The inference time per image is accessible through the classifier. Here you can see hardware vs software execution times per image in microseconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hw_time = [lfcW1A1_classifier.usecPerImage,\n",
    "           lfcW1A2_classifier.usecPerImage,\n",
    "           lfcW2A2_classifier.usecPerImage]\n",
    "sw_time = [sw_lfcW1A1_classifier.usecPerImage,\n",
    "           sw_lfcW1A2_classifier.usecPerImage]\n",
    "\n",
    "x_axis = ('W1A1', 'W1A2', 'W2A2')\n",
    "\n",
    "y_pos = np.arange(len(x_axis))\n",
    "plt.bar(y_pos-0.25, hw_time, 0.25)\n",
    "plt.bar(y_pos+0.25, sw_time, 0.25)\n",
    "plt.xticks(y_pos, x_axis)\n",
    "plt.legend([\"hardware\",\"software\"])\n",
    "plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy W2A2:  10.0\n"
     ]
    }
   ],
   "source": [
    "#compare against labels\n",
    "# countRight = 0\n",
    "# for idx in range(len(labels)):\n",
    "#     if labels[idx] == result_W1A1[idx]:\n",
    "#         countRight += 1\n",
    "# accuracyW1A1 = countRight*100/len(labels)\n",
    "\n",
    "# countRight = 0\n",
    "# for idx in range(len(labels)):\n",
    "#     if labels[idx] == result_W1A2[idx]:\n",
    "#         countRight += 1\n",
    "# accuracyW1A2 = countRight*100/len(labels)\n",
    "\n",
    "countRight = 0\n",
    "labels = labels[:10]\n",
    "for idx in range(len(labels)):\n",
    "    if labels[idx] == sw_resultW2A2[idx]:\n",
    "        countRight += 1\n",
    "accuracyW2A2 = countRight*100/len(labels)\n",
    "\n",
    "# print(\"Accuracy W1A1: \", accuracyW1A1)\n",
    "# print(\"Accuracy W1A2: \", accuracyW1A2)\n",
    "print(\"Accuracy W2A2: \", accuracyW2A2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reset the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Xlnk\n",
    "\n",
    "xlnk = Xlnk()\n",
    "xlnk.xlnk_reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
